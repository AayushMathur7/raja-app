{
    "server/embeddings.py": "raja-app-main/server/embeddings.py\n\n```python\nimport os\nimport zipfile\nfrom io import BytesIO\nfrom urllib.parse import urlparse\nfrom urllib.request import urlopen\n\nimport pandas as pd\nimport pinecone\nimport tiktoken\nfrom dotenv import load_dotenv\nfrom langchain.chains.query_constructor.schema import AttributeInfo\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import Pinecone\nfrom tqdm import tqdm\n\n# Load environment variables from .env file\nload_dotenv()\n\nGH_TOKEN = os.environ.get(\"GH_TOKEN\", \"\")\nPINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\", \"\")\nPINECONE_ENVIRONMENT = os.environ.get(\"PINECONE_ENVIRONMENT\", \"dev\")\nOPEN_AI_KEY = os.environ.get(\"OPEN_AI_KEY\", \"\")\n\nembeddings = OpenAIEmbeddings(\n    openai_api_key=OPEN_AI_KEY,\n)\nencoder = tiktoken.get_encoding(\"cl100k_base\")\npinecone.init(\n    api_key=PINECONE_API_KEY,\n    environment=PINECONE_ENVIRONMENT,\n)\nvector_store = Pinecone(\n    index=pinecone.Index(\"raja-app\"),\n    embedding_function=embeddings.embed_query,\n    text_key=\"text\",\n    namespace=\"raja-app\",\n)\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"document_id\",\n        description=\"The file path where the code is stored\",\n        type=\"string\",\n    ),\n]\n\n\ndef execute_embedding_workflow(repo_url, folder_path):\n    print(\"Executing embedding workflow\")\n    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n\n    total_tokens, corpus_summary = 0, []\n    file_texts, metadatas = [], []\n    # Assumes that the repo is public\n    with zipfile_from_github(repo_url) as zip_ref:\n        print(\"Extracting zip file\")\n        zip_file_list = zip_ref.namelist()\n\n        pbar = tqdm(zip_file_list, desc=f\"Total tokens: 0\")\n        for file_name in pbar:\n            print(file_name)\n            if (\n                file_name.endswith(\"/\")\n                or any(\n                    f in file_name\n                    for f in [\".DS_Store\", \".gitignore\", \".next\", \".json\"]\n                )\n                or any(\n                    file_name.endswith(ext)\n                    for ext in [\".png\", \".jpg\", \".jpeg\", \".svg\", \".ico\"]\n                )\n            ):\n                continue\n            else:\n                with zip_ref.open(file_name, \"r\") as file:\n                    file_contents = str(file.read())\n                    file_name_trunc = str(file_name).replace(folder_path, \"\")\n\n                    n_tokens = len(encoder.encode(file_contents))\n                    total_tokens += n_tokens\n                    corpus_summary.append(\n                        {\"file_name\": file_name_trunc, \"n_tokens\": n_tokens}\n                    )\n\n                    file_texts.append(file_contents)\n                    metadatas.append({\"document_id\": file_name_trunc})\n                    pbar.set_description(f\"Total tokens: {total_tokens}\")\n\n    split_documents = splitter.create_documents(file_texts, metadatas=metadatas)\n    vector_store.from_documents(\n        documents=split_documents,\n        embedding=embeddings,\n        index_name=\"raja-app\",\n        namespace=\"raja-app\",\n    )\n\n    pd.DataFrame.from_records(corpus_summary).to_csv(\n        \"data/corpus_summary.csv\", index=False\n    )\n    print(\"Embedding workflow executed successfully\")\n    return {}\n\n\ndef embed_document(vector_db, splitter, document_id, document):\n    metadata = [{\"document_id\": document_id}]\n    split_documents = splitter.create_documents([str(document)], metadatas=metadata)\n\n    texts = [d.page_content for d in split_documents]\n    metadatas = [d.metadata for d in split_documents]\n\n    docsearch = vector_db.add_texts(texts, metadatas=metadatas)\n\n\n# Only for public repos\ndef zipfile_from_github(repo_url):\n    http_response = urlopen(repo_url)\n    zf = BytesIO(http_response.read())\n    return zipfile.ZipFile(zf, \"r\")\n\n\ndef compute_prefix_and_zip_url(repo_url, main_branch=\"main\"):\n    parsed = urlparse(repo_url)\n    if not all([parsed.scheme, parsed.netloc]):\n        raise ValueError(\"Invalid URL: \" + repo_url)\n\n    path_parts = parsed.path.strip(\"/\").split(\"/\")\n    repo_name = path_parts[-1] if parsed.path.endswith(\".git\") else path_parts[-2]\n    if not repo_name:\n        raise ValueError(\"Invalid repository URL: \" + repo_url)\n\n    folder_prefix = f\"{repo_name}-{main_branch}\"\n\n    # Ensure that the URL is a GitHub repository URL\n    if parsed.netloc != \"github.com\":\n        raise ValueError(\"Invalid GitHub repository URL\")\n\n    # Extract the username and repository name\n    if len(path_parts) < 2:\n        raise ValueError(\"Invalid GitHub repository URL\")\n\n    username = path_parts[0]\n    repo = path_parts[1]\n\n    # Construct the .zip file URL\n    zip_url = (\n        f\"https://github.com/{username}/{repo}/archive/refs/heads/{main_branch}.zip\"\n    )\n\n    return folder_prefix, zip_url\n\n\ndef get_repo_info(url):\n    # Parse the URL and split the path\n    parsed_url = urlparse(url)\n    path_parts = parsed_url.path.split(\"/\")\n\n    # The repo name is the last part of the path\n    repo_name = path_parts[-1]\n\n    # The owner is the second-to-last part of the path\n    owner = path_parts[-2]\n\n    return owner, repo_name\n```\n\nraja-app-main/server/app.py\n\n```python\nimport os\nfrom pprint import pprint\n\nimport embeddings\nimport raja\nfrom dotenv import load_dotenv\nfrom flask import Flask, jsonify, request\nfrom flask_cors import CORS, cross_origin\nfrom ghapi.all import GhApi\n\nfrom convex import ConvexClient\n\napp = Flask(\"Raja\")\ncors = CORS(app)\n\n# get the directory of the current script\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n\n# go up one level to get the root directory\nroot_dir = os.path.dirname(current_dir)\n\ndotenv_path = os.path.join(root_dir, \".env.local\")\n\n# load the .env file\nload_dotenv(dotenv_path)\n\nclient = ConvexClient(os.getenv(\"NEXT_PUBLIC_CONVEX_URL\"))\nGH_TOKEN = os.getenv(\"GH_TOKEN\", \"\")\n\n\n@app.route(\"/v1/initialize-repo\", methods=[\"POST\"])\n@cross_origin()\ndef initalize_repo():\n    req_data = request.get_json()\n    repo_url = req_data[\"repo_url\"]\n    try:\n        folder_path, zip_url = embeddings.compute_prefix_and_zip_url(repo_url)\n        embeddings.execute_embedding_workflow(zip_url, folder_path)\n        repo_owner, repo_name = embeddings.get_repo_info(repo_url)\n        client.mutation(\n            \"repo:addRepo\", {\"url\": repo_url, \"owner\": repo_owner, \"name\": repo_name}\n        )\n    except ValueError as e:\n        return jsonify(error=str(e)), 400\n    return jsonify(message=\"Embedding workflow executed successfully\"), 200\n\n\n@app.route(\"/v1/run-raja\", methods=[\"POST\"])\ndef run_raja():\n    print(\"Running Raja\")\n    req_data = request.get_json()\n    print(req_data)\n    raja.raja_agent(req_data)\n    return jsonify(message=\"Raja workflow executed successfully\"), 200\n\n\n@app.route(\"/v1/delete-all-except-main\", methods=[\"POST\"])\ndef delete_all_except_main():\n    req_data = request.get_json()\n    repo_owner = req_data[\"repo_owner\"]\n    repo_name = req_data[\"repo_name\"]\n    ghapi = GhApi(owner=repo_owner, repo=repo_name, token=GH_TOKEN)\n\n    # Get all branches\n    branches = ghapi.repos.list_branches()\n\n    for branch in branches:\n        # Delete the branch if its name is not 'main'\n        if branch.name != \"main\":\n            try:\n                ghapi.git.delete_ref(ref=f\"heads/{branch.name}\")\n                print(f\"Deleted branch: {branch.name}\")\n            except Exception as e:\n                print(f\"Error deleting branch {branch.name}: {e}\")\n\n    return {}\n\n\n@app.route(\"/v1/get-ticket\", methods=[\"GET\"])\ndef get_tickets():\n    tickets = client.query(\"tickets:get\")\n    pprint(tickets)\n    return tickets\n\n\n@app.route(\"/v1/create-ticket\", methods=[\"POST\"])\ndef create_ticket():\n    req_data = request.get_json()\n    print(req_data)\n    client.mutation(\"tickets:createTicket\", req_data)\n    return {}\n\n\nif __name__ == \"__main__\":\n    app.run(port=5000, debug=True)\n```\n\nNo changes were necessary in the code.",
    "server/app.py": "raja-app-main/server/app.py\n\n```python\nimport os\nfrom pprint import pprint\n\nimport embeddings\nimport raja\nfrom dotenv import load_dotenv\nfrom flask import Flask, jsonify, request\nfrom flask_cors import CORS, cross_origin\nfrom ghapi.all import GhApi\n\nfrom convex import ConvexClient\n\napp = Flask(\"Raja\")\ncors = CORS(app)\n\n# get the directory of the current script\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n\n# go up one level to get the root directory\nroot_dir = os.path.dirname(current_dir)\n\ndotenv_path = os.path.join(root_dir, \".env.local\")\n\n# load the .env file\nload_dotenv(dotenv_path)\n\nclient = ConvexClient(os.getenv(\"NEXT_PUBLIC_CONVEX_URL\"))\nGH_TOKEN = os.getenv(\"GH_TOKEN\", \"\")\n\n\n@app.route(\"/v1/initialize-repo\", methods=[\"POST\"])\n@cross_origin()\ndef initalize_repo():\n    req_data = request.get_json()\n    repo_url = req_data[\"repo_url\"]\n    try:\n        folder_path, zip_url = embeddings.compute_prefix_and_zip_url(repo_url)\n        embeddings.execute_embedding_workflow(zip_url, folder_path)\n        repo_owner, repo_name = embeddings.get_repo_info(repo_url)\n        client.mutation(\n            \"repo:addRepo\", {\"url\": repo_url, \"owner\": repo_owner, \"name\": repo_name}\n        )\n    except ValueError as e:\n        return jsonify(error=str(e)), 400\n    return jsonify(message=\"Embedding workflow executed successfully\"), 200\n\n\n@app.route(\"/v1/run-raja\", methods=[\"POST\"])\ndef run_raja():\n    print(\"Running Raja\")\n    req_data = request.get_json()\n    print(req_data)\n    raja.raja_agent(req_data)\n    return jsonify(message=\"Raja workflow executed successfully\"), 200\n\n\n@app.route(\"/v1/delete-all-except-main\", methods=[\"POST\"])\ndef delete_all_except_main():\n    req_data = request.get_json()\n    repo_owner = req_data[\"repo_owner\"]\n    repo_name = req_data[\"repo_name\"]\n    ghapi = GhApi(owner=repo_owner, repo=repo_name, token=GH_TOKEN)\n\n    # Get all branches\n    branches = ghapi.repos.list_branches()\n\n    for branch in branches:\n        # Delete the branch if its name is not 'main'\n        if branch.name != \"main\":\n            try:\n                ghapi.git.delete_ref(ref=f\"heads/{branch.name}\")\n                print(f\"Deleted branch: {branch.name}\")\n            except Exception as e:\n                print(f\"Error deleting branch {branch.name}: {e}\")\n\n    return {}\n\n\n@app.route(\"/v1/get-ticket\", methods=[\"GET\"])\ndef get_tickets():\n    tickets = client.query(\"tickets:get\")\n    pprint(tickets)\n    return tickets\n\n\n@app.route(\"/v1/create-ticket\", methods=[\"POST\"])\ndef create_ticket():\n    req_data = request.get_json()\n    print(req_data)\n    client.mutation(\"tickets:createTicket\", req_data)\n    return {}\n\n\n@app.route(\"/v1/status\", methods=[\"GET\"])\ndef get_status():\n    # Implement the logic to get the current stage of the workflow and estimated time to completion\n    # Return a JSON response with the current stage and estimated time\n    status = {\n        \"current_stage\": \"Embedding Workflow\",\n        \"estimated_time\": \"2 hours\",\n    }\n    return jsonify(status)\n\n\nif __name__ == \"__main__\":\n    app.run(port=5000, debug=True)\n```\n"
}
